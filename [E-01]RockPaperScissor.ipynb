{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddeceea9",
   "metadata": {},
   "source": [
    "이미지 사이즈변경을 위해 PIL 라이브러리를 사용한다.\n",
    "만약 PIL 라이브러리가 설치되지 않은 경우 pip install pillow 를 통해 설치가 가능하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25deae08",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'PIL'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mglob\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'PIL'"
     ]
    }
   ],
   "source": [
    "from PIL import *\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8313dc49",
   "metadata": {},
   "source": [
    "준비한 가위이미지를 28x28 사이즈로 resize 한다.\n",
    "동일한 방법으로 보와 바위도 resize 해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4443f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /aiffel/aiffel/rock_scissor_paper/scissor\n",
      "가위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/scissor\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e107409b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /aiffel/aiffel/rock_scissor_paper/rock\n",
      "바위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/rock\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"바위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4235eb61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /aiffel/aiffel/rock_scissor_paper/paper\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/paper\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"보 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4294b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 300 입니다.\n",
      "x_train shape: (300, 28, 28, 3)\n",
      "y_train shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_data(img_path, number_of_data = 300):\n",
    "        # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=28\n",
    "    color=3 # 1이면 흑백 , 3이면 컬러\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42925c6c",
   "metadata": {},
   "source": [
    "위의 출력값인 x_train 데이터는(데이터개수, 이미지크지 x, 이미지 크기y, 채널 수) 형태로 생성됨\n",
    "컬러 이미지이기 때문에 R,G,B 값으로 표현되기 때문에 3개의 채널수를 가진다. \n",
    "만약 흑백 이미지라면 1개의 채널을 가지게 된다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a938ad",
   "metadata": {},
   "source": [
    "불러온 데이터 확인해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b57157",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(x_train[0])\n",
    "print('라벨: ', y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6b06ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_14 (Conv2D)           (None, 26, 26, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 11, 11, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 64)                51264     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 56,547\n",
      "Trainable params: 56,547\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 네트워크는 tf와 tf내에 속한 keras로 구축\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "n_channel_1=16\n",
    "n_channel_2=32\n",
    "n_dense=64\n",
    "n_train_epoch=15\n",
    "\n",
    "\n",
    "model=keras.models.Sequential() # Sequential API를 이용해 네트워크 model변수에 초기화\n",
    "# conv2D레이어에 이미지 특징 수, 입력 이미지의 형태 등을 넣고 MaxPooling2D를 통해 맥스 풀링 연산을 함\n",
    "# dense 레이어는 분류기에 사용되는 뉴런의 숫자를 입력하고 마지막 Dense 레이어에는 결과에 도출할 클래스 수를 입력함\n",
    "\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376c073a",
   "metadata": {},
   "source": [
    "epochs 값은 10으로 지정해서 학습 시킴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e59369",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0781 - accuracy: 0.3900\n",
      "Epoch 2/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0097 - accuracy: 0.5033\n",
      "Epoch 3/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.8955 - accuracy: 0.7133\n",
      "Epoch 4/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.7496 - accuracy: 0.7667\n",
      "Epoch 5/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.6613 - accuracy: 0.7033\n",
      "Epoch 6/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5617 - accuracy: 0.8067\n",
      "Epoch 7/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5022 - accuracy: 0.8567\n",
      "Epoch 8/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4394 - accuracy: 0.8667\n",
      "Epoch 9/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3803 - accuracy: 0.8933\n",
      "Epoch 10/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3427 - accuracy: 0.9100\n",
      "Epoch 11/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3392 - accuracy: 0.8867\n",
      "Epoch 12/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2670 - accuracy: 0.9333\n",
      "Epoch 13/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2324 - accuracy: 0.9200\n",
      "Epoch 14/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2097 - accuracy: 0.9467\n",
      "Epoch 15/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1795 - accuracy: 0.9500\n",
      "Epoch 16/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1328 - accuracy: 0.9467\n",
      "Epoch 17/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1108 - accuracy: 0.9767\n",
      "Epoch 18/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0891 - accuracy: 0.9800\n",
      "Epoch 19/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0765 - accuracy: 0.9733\n",
      "Epoch 20/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0634 - accuracy: 0.9933\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f62c1fa36d0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer = 'adam',\n",
    "             loss = 'sparse_categorical_crossentropy',\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "model.fit(x_train_norm, y_train, epochs=10) # 10번 학습을 진행 시킴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e0cbb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 이미지 디렉토리 경로:  /aiffel/aiffel/rock_scissor_paper/scissor\n",
      "학습데이터(x_train)의 이미지 개수는 0 입니다.\n",
      "x_test shape: (300, 28, 28, 3)\n",
      "x_test_norm shape: (300, 28, 28, 3)\n",
      "y_test shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "print(\"test 이미지 디렉토리 경로: \", image_dir_path)\n",
    "(x_test, y_test)=load_data(image_dir_path)\n",
    "x_test_norm = x_test/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_test shape: {}\".format(x_test.shape))\n",
    "print(\"x_test_norm shape: {}\".format(x_test_norm.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1968ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 1.5365 - accuracy: 0.0000e+00\n",
      "test_loss: 1.5365084409713745 \n",
      "test_accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test_norm, y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd90ce07",
   "metadata": {},
   "source": [
    "1차 결과물"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d748fb65",
   "metadata": {},
   "source": [
    "학습 데이터 개수 확장시키기(총 이미지 3012개)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254f1dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 3012 입니다.\n",
      "x_train shape: (3012, 28, 28, 3)\n",
      "y_train shape: (3012,)\n"
     ]
    }
   ],
   "source": [
    "def load_data3(img_path, number_of_data=3012):  # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=28\n",
    "    color=3 # 1이면 흑백 , 3이면 컬러\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "\n",
    "image_dir_path4 = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test\"\n",
    "(x_train, y_train)=load_data3(image_dir_path4)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2b6810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "95/95 [==============================] - 1s 3ms/step - loss: 0.0040 - accuracy: 0.9990\n",
      "Epoch 2/10\n",
      "95/95 [==============================] - 0s 3ms/step - loss: 8.8030e-04 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "95/95 [==============================] - 0s 3ms/step - loss: 0.0082 - accuracy: 0.9970\n",
      "Epoch 4/10\n",
      "95/95 [==============================] - 0s 3ms/step - loss: 6.6831e-04 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "95/95 [==============================] - 0s 3ms/step - loss: 4.8735e-04 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "95/95 [==============================] - 0s 3ms/step - loss: 3.9957e-04 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "95/95 [==============================] - 0s 3ms/step - loss: 3.2458e-04 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "95/95 [==============================] - 0s 3ms/step - loss: 2.9723e-04 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "95/95 [==============================] - 0s 3ms/step - loss: 3.0732e-04 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "95/95 [==============================] - 0s 3ms/step - loss: 2.4767e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f639e61e700>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train_norm, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96986a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 8.8768 - accuracy: 0.0000e+00\n",
      "test_loss: 8.876762390136719 \n",
      "test_accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test_norm, y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f29309",
   "metadata": {},
   "source": [
    "[회고]\n",
    "모델을 구축하기전에 충분한 데이터 이미지가 필요하며, 그에 맞는 파라미터 값을 정해주어야한다.\n",
    "\n",
    "1. 이미지 데이터가 224x224에서 28x28로 변경되면서 생긴 해상도 저하를 생각해야한다.\n",
    "\n",
    "2. 가위바위보의 경우 데이터가 많을수록 주변환경을 고려를 많이 해야한다.\n",
    "- 인종, 조명, 주변환경(배경에 오브젝트가 없어야 더 인식하기 좋음) ,가위(특히나 가위의 경우 엄지검지,검지중지,중지약지,약지소지) 이런식으로 여러가지의 종류를 고려해야함\n",
    "\n",
    "3. 더 많고 다양한 데이터들을 수집하여 적절한 하이퍼파라미터와 히든 레이어를 결정하게 된다면 더 정확하지 않을까?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
